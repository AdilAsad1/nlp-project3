{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hik_9ZBwIW73"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read files\n",
        "text_test = []\n",
        "text_train = []\n",
        "labels_train = []\n",
        "labels_test = []\n",
        "\n",
        "# read the contents of text_test.txt and store it in text_test list\n",
        "with open('text_test.txt', 'r', encoding='ISO-8859-1') as file:\n",
        "    for line in file:\n",
        "        text_test.append(line.strip())\n",
        "\n",
        "# read the contents of text_train.txt and store it in text_train list\n",
        "with open('text_train.txt', 'r', encoding='ISO-8859-1') as file:\n",
        "    for line in file:\n",
        "        text_train.append(line.strip())\n",
        "\n",
        "# read the contents of labels_train.txt and store it in labels_train list\n",
        "with open('label_train.txt', 'r', encoding='ISO-8859-1') as file:\n",
        "    for line in file:\n",
        "        labels_train.append(line.strip())\n",
        "\n",
        "# read the contents of labels_test.txt and store it in labels_test list\n",
        "with open('label_test.txt', 'r',encoding='ISO-8859-1') as file:\n",
        "    for line in file:\n",
        "        labels_test.append(line.strip())\n"
      ],
      "metadata": {
        "id": "ImSXRGEZIYBF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text_test\n",
        "#text_train\n",
        "#labels_test\n",
        "#labels_train"
      ],
      "metadata": {
        "id": "6dGsLzk5JPW_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(text_train, labels_train):\n",
        "    # Create a vocabulary of all words in the text_train data\n",
        "    vocabulary = set()\n",
        "    for document in text_train:\n",
        "        vocabulary |= set(document.split())\n",
        "    vocabulary = list(vocabulary)\n",
        "\n",
        "    # Initialize a dictionary to store the word count for each class\n",
        "    class_word_count = {c: collections.defaultdict(int) for c in set(labels_train)}\n",
        "\n",
        "    # Count the number of words in each document for each class\n",
        "    for document, label in zip(text_train, labels_train):\n",
        "        for word in document.split():\n",
        "            class_word_count[label][word] += 1\n",
        "\n",
        "    # Compute the class probabilities\n",
        "    class_probabilities = dict(collections.Counter(labels_train))\n",
        "    for label in class_probabilities:\n",
        "        class_probabilities[label] /= len(labels_train)\n",
        "\n",
        "    # Compute the word probabilities for each class\n",
        "    word_probabilities = {c: dict() for c in set(labels_train)}\n",
        "    for label in class_word_count:\n",
        "        total_word_count = sum(class_word_count[label].values())\n",
        "        for word in vocabulary:\n",
        "            word_probabilities[label][word] = (class_word_count[label][word] + 1) / (total_word_count + len(vocabulary))\n",
        "\n",
        "    return vocabulary, class_probabilities, word_probabilities\n",
        "\n",
        "def predict_naive_bayes(text, vocabulary, class_probabilities, word_probabilities):\n",
        "    # Compute the class probabilities for each document\n",
        "    document_probabilities = {c: np.log(class_probabilities[c]) for c in class_probabilities}\n",
        "    for word in text.split():\n",
        "        if word in vocabulary:\n",
        "            for label in word_probabilities:\n",
        "                document_probabilities[label] += np.log(word_probabilities[label][word])\n",
        "    return max(document_probabilities, key=lambda c: document_probabilities[c])\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "vocabulary, class_probabilities, word_probabilities = train_naive_bayes(text_train, labels_train)\n",
        "\n",
        "# Predict the class labels for the text_test data\n",
        "predicted_labels = [predict_naive_bayes(text, vocabulary, class_probabilities, word_probabilities) for text in text_test]\n"
      ],
      "metadata": {
        "id": "gIGAEiglJZ7j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predicted_labels, actual_labels):\n",
        "    return sum(predicted == actual for predicted, actual in zip(predicted_labels, actual_labels)) / len(actual_labels)\n",
        "\n",
        "# Predict the class labels for the text_test data\n",
        "predicted_labels = [predict_naive_bayes(text, vocabulary, class_probabilities, word_probabilities) for text in text_test]\n",
        "\n",
        "# Calculate the accuracy of the classifier\n",
        "accuracy = calculate_accuracy(predicted_labels, labels_test)\n",
        "print(\"Accuracy:\", accuracy*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjFbsEyHKmNn",
        "outputId": "170f240b-9ef7-4040-b5d9-e677f76f5980"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 76.58975801913337\n"
          ]
        }
      ]
    }
  ]
}